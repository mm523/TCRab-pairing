{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script can only be run if pre-processed data is available. Otherwise, start from apply_stitchr_tanno.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyrepseq as prs\n",
    "import os\n",
    "import numpy as np\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1 memory.txt',\n",
       " 'A1 naive.txt',\n",
       " 'A2 memory.txt',\n",
       " 'A2 naive.txt',\n",
       " 'B1 memory.txt',\n",
       " 'B1 naive.txt',\n",
       " 'B2 memory.txt',\n",
       " 'B2 naive.txt',\n",
       " 'C1 memory.txt',\n",
       " 'C1 naive.txt',\n",
       " 'C2 memory.txt',\n",
       " 'C2 naive.txt',\n",
       " 'D1 replicate.txt',\n",
       " 'D1.txt',\n",
       " 'D2 replicate.txt',\n",
       " 'D2.txt',\n",
       " 'E1 replicate.txt',\n",
       " 'E1.txt',\n",
       " 'E2 replicate.txt',\n",
       " 'E2.txt',\n",
       " 'F1.txt',\n",
       " 'F2.txt',\n",
       " 'X replicate.txt',\n",
       " 'X.txt',\n",
       " 'Y replicate.txt',\n",
       " 'Y.txt',\n",
       " 'Z replicate.txt',\n",
       " 'Z.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = '/path/to/folder/'\n",
    "\n",
    "os.listdir(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function allows me to do the same preprocessing as in Mayer and Callan, 2023. \n",
    "\n",
    "This cleans up the dataset by: (1) removing invariant, (2) removing overlap between memory and naive and (3) removing identical nucleotide sequences, which are unlikely to have occurred and are probably a by-product of the PCR protocol.\n",
    "\n",
    "Function from: https://github.com/andim/paper_coincidences/blob/main/scripts/process_tanno_pruning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_pruning(f, myfile):\n",
    "    # sort by clone sizes\n",
    "    df = pd.read_csv(f + myfile, sep = '\\t')\n",
    "    print('Initial size: ', df.shape)\n",
    "    df = df.sort_values('Clustered', ascending=False)\n",
    "\n",
    "    valid_light = df['CDRL3_AA'].apply(prs.isvalidcdr3)\n",
    "    valid_heavy = df['CDRH3_AA'].apply(prs.isvalidcdr3)\n",
    "    before = len(df)\n",
    "    df = df[valid_light & valid_heavy]\n",
    "    print(before, np.sum(~valid_light), np.sum(~valid_heavy), len(df))\n",
    "\n",
    "    # what prunings will we do?\n",
    "    invariants = True\n",
    "    memory_naive = True\n",
    "    unique_nt = True\n",
    "\n",
    "    if invariants:\n",
    "        # now remove the invariant cells, defined by the following alpha chain V/J pairs\n",
    "        invariant = [('TRAV1-2', 'TRAJ33'), \n",
    "                    ('TRAV1-2', 'TRAJ12'),\n",
    "                    ('TRAV1-2', 'TRAJ20'),\n",
    "                    ('TRAV10', 'TRAJ18')]\n",
    "        invariant_joined = [s1+'_'+s2 for s1,s2 in invariant]\n",
    "\n",
    "        mask = (df['VL'] + '_' + df['JL']).isin(invariant_joined)\n",
    "        df = df[~mask]\n",
    "        print('invariant filtered', sum(mask))\n",
    "\n",
    "    if memory_naive:\n",
    "        if 'naive' in myfile:\n",
    "            dfmem = pd.read_csv(f + myfile.replace('naive', 'memory'), sep='\\t')\n",
    "            A = df['CDRH3_AA'] + '_' + df['CDRL3_AA']\n",
    "            B = dfmem['CDRH3_AA'] + '_' + dfmem['CDRL3_AA']\n",
    "            mask = A.isin(B)\n",
    "            df = df[~mask]\n",
    "            print('memory overlap filtered', sum(mask))\n",
    "\n",
    "    if unique_nt:\n",
    "        before = len(df)\n",
    "        df = df.drop_duplicates('CDRH3_NT', keep='first')\n",
    "        df = df.drop_duplicates('CDRL3_NT', keep='first')\n",
    "        print('nt duplicates filtered', before-len(df))\n",
    "    \n",
    "    print('After preprocessing: ', df.shape)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 memory.txt\n",
      "Initial size:  (28148, 12)\n",
      "28148 212 72 27864\n",
      "invariant filtered 136\n",
      "nt duplicates filtered 2852\n",
      "After preprocessing:  (24876, 12)\n",
      "A1 naive.txt\n",
      "Initial size:  (17274, 12)\n",
      "17274 159 53 17063\n",
      "invariant filtered 18\n",
      "memory overlap filtered 48\n",
      "nt duplicates filtered 2098\n",
      "After preprocessing:  (14899, 12)\n",
      "A2 memory.txt\n",
      "Initial size:  (30121, 12)\n",
      "30121 252 82 29788\n",
      "invariant filtered 158\n",
      "nt duplicates filtered 4242\n",
      "After preprocessing:  (25388, 12)\n",
      "A2 naive.txt\n",
      "Initial size:  (42335, 12)\n",
      "42335 487 156 41694\n",
      "invariant filtered 53\n",
      "memory overlap filtered 213\n",
      "nt duplicates filtered 5510\n",
      "After preprocessing:  (35918, 12)\n",
      "B1 memory.txt\n",
      "Initial size:  (25422, 12)\n",
      "25422 146 32 25244\n",
      "invariant filtered 35\n",
      "nt duplicates filtered 2809\n",
      "After preprocessing:  (22400, 12)\n",
      "B1 naive.txt\n",
      "Initial size:  (46343, 12)\n",
      "46343 305 100 45940\n",
      "invariant filtered 37\n",
      "memory overlap filtered 159\n",
      "nt duplicates filtered 5100\n",
      "After preprocessing:  (40644, 12)\n",
      "B2 memory.txt\n",
      "Initial size:  (37531, 12)\n",
      "37531 318 90 37128\n",
      "invariant filtered 55\n",
      "nt duplicates filtered 8985\n",
      "After preprocessing:  (28088, 12)\n",
      "B2 naive.txt\n",
      "Initial size:  (65238, 12)\n",
      "65238 465 123 64651\n",
      "invariant filtered 38\n",
      "memory overlap filtered 233\n",
      "nt duplicates filtered 11399\n",
      "After preprocessing:  (52981, 12)\n",
      "C1 memory.txt\n",
      "Initial size:  (44777, 12)\n",
      "44777 318 77 44385\n",
      "invariant filtered 101\n",
      "nt duplicates filtered 8405\n",
      "After preprocessing:  (35879, 12)\n",
      "C1 naive.txt\n",
      "Initial size:  (57166, 12)\n",
      "57166 412 66 56688\n",
      "invariant filtered 51\n",
      "memory overlap filtered 480\n",
      "nt duplicates filtered 7738\n",
      "After preprocessing:  (48419, 12)\n",
      "C2 memory.txt\n",
      "Initial size:  (18334, 12)\n",
      "18334 138 31 18165\n",
      "invariant filtered 28\n",
      "nt duplicates filtered 5312\n",
      "After preprocessing:  (12825, 12)\n",
      "C2 naive.txt\n",
      "Initial size:  (26320, 12)\n",
      "26320 211 50 26059\n",
      "invariant filtered 18\n",
      "memory overlap filtered 119\n",
      "nt duplicates filtered 4091\n",
      "After preprocessing:  (21831, 12)\n",
      "D1 replicate.txt\n",
      "Initial size:  (22040, 12)\n",
      "22040 54 36 21950\n",
      "invariant filtered 165\n",
      "nt duplicates filtered 1177\n",
      "After preprocessing:  (20608, 12)\n",
      "D1.txt\n",
      "Initial size:  (7670, 12)\n",
      "7670 12 7 7651\n",
      "invariant filtered 64\n",
      "nt duplicates filtered 240\n",
      "After preprocessing:  (7347, 12)\n",
      "D2 replicate.txt\n",
      "Initial size:  (20450, 12)\n",
      "20450 43 24 20383\n",
      "invariant filtered 162\n",
      "nt duplicates filtered 840\n",
      "After preprocessing:  (19381, 12)\n",
      "D2.txt\n",
      "Initial size:  (34369, 12)\n",
      "34369 135 114 34124\n",
      "invariant filtered 224\n",
      "nt duplicates filtered 2095\n",
      "After preprocessing:  (31805, 12)\n",
      "E1 replicate.txt\n",
      "Initial size:  (53215, 12)\n",
      "53215 353 66 52797\n",
      "invariant filtered 510\n",
      "nt duplicates filtered 4122\n",
      "After preprocessing:  (48165, 12)\n",
      "E1.txt\n",
      "Initial size:  (29632, 12)\n",
      "29632 218 33 29381\n",
      "invariant filtered 325\n",
      "nt duplicates filtered 1914\n",
      "After preprocessing:  (27142, 12)\n",
      "E2 replicate.txt\n",
      "Initial size:  (16963, 12)\n",
      "16963 106 14 16844\n",
      "invariant filtered 259\n",
      "nt duplicates filtered 947\n",
      "After preprocessing:  (15638, 12)\n",
      "E2.txt\n",
      "Initial size:  (45312, 12)\n",
      "45312 320 40 44953\n",
      "invariant filtered 520\n",
      "nt duplicates filtered 4674\n",
      "After preprocessing:  (39759, 12)\n",
      "F1.txt\n",
      "Initial size:  (85193, 12)\n",
      "85193 675 2312 82219\n",
      "invariant filtered 806\n",
      "nt duplicates filtered 14878\n",
      "After preprocessing:  (66535, 12)\n",
      "F2.txt\n",
      "Initial size:  (25942, 12)\n",
      "25942 153 588 25204\n",
      "invariant filtered 297\n",
      "nt duplicates filtered 970\n",
      "After preprocessing:  (23937, 12)\n",
      "X replicate.txt\n",
      "Initial size:  (36375, 12)\n",
      "36375 223 64 36088\n",
      "invariant filtered 170\n",
      "nt duplicates filtered 4145\n",
      "After preprocessing:  (31773, 12)\n",
      "X.txt\n",
      "Initial size:  (27316, 12)\n",
      "27316 172 36 27109\n",
      "invariant filtered 127\n",
      "nt duplicates filtered 2912\n",
      "After preprocessing:  (24070, 12)\n",
      "Y replicate.txt\n",
      "Initial size:  (42022, 12)\n",
      "42022 340 86 41598\n",
      "invariant filtered 289\n",
      "nt duplicates filtered 3967\n",
      "After preprocessing:  (37342, 12)\n",
      "Y.txt\n",
      "Initial size:  (43679, 12)\n",
      "43679 368 112 43203\n",
      "invariant filtered 345\n",
      "nt duplicates filtered 2911\n",
      "After preprocessing:  (39947, 12)\n",
      "Z replicate.txt\n",
      "Initial size:  (22535, 12)\n",
      "22535 213 46 22277\n",
      "invariant filtered 103\n",
      "nt duplicates filtered 1349\n",
      "After preprocessing:  (20825, 12)\n",
      "Z.txt\n",
      "Initial size:  (13801, 12)\n",
      "13801 124 30 13647\n",
      "invariant filtered 53\n",
      "nt duplicates filtered 561\n",
      "After preprocessing:  (13033, 12)\n"
     ]
    }
   ],
   "source": [
    "alldf = []\n",
    "\n",
    "for myfile in os.listdir(f):\n",
    "    print(myfile)    \n",
    "    df = df_pruning(f, myfile)\n",
    "    df['subject'] = myfile[0:2].strip(' .')\n",
    "    df['sample'] = myfile.strip('.txt')\n",
    "    alldf.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.concat(alldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('data/Tanno_combined.csv.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JupPytest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b3713aeab77f512316ecb2c46a3c343366ab1de98e68eb8bac1672750185c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
